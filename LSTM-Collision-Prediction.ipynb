{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUxka0gR1NHc"
   },
   "outputs": [],
   "source": [
    "# Install TensorFlow\n",
    "# !pip install -q tensorflow-gpu==2.0.0-beta1\n",
    "\n",
    "#try:\n",
    "#  %tensorflow_version 2.x  # Colab only.\n",
    "#except Exception:\n",
    "#  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lC4e13YFVzHp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import string\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klkXh-cDyFhX"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLaG2e5zk64W"
   },
   "outputs": [],
   "source": [
    "#with open('/content/drive/My Drive/foo.txt', 'w') as f:\n",
    "#  f.write('Hello Google Drive!')\n",
    "#!cat /content/drive/My\\ Drive/foo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhiceB1r1jp4"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8zBUYvy1kiH"
   },
   "outputs": [],
   "source": [
    "#import io\n",
    "#Data_Frame = pd.read_csv(io.BytesIO(uploaded['MITLL_Correlated_RNN_Data.csv']))\n",
    "\n",
    "# Dataset is now stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2BUax43pkPR"
   },
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S00sWFl1Dwlc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BjdP2Ic9agv"
   },
   "source": [
    "# New Section : RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0QfXUTi42W1"
   },
   "outputs": [],
   "source": [
    "# More imports\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, GRU, LSTM, Dense, Flatten, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ib5-VKJQYLtc"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_1 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_1.csv')#, header=None)  \n",
    "Data_Frame_1 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_1.csv')#, header=None)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlnRPEfGb0iX"
   },
   "outputs": [],
   "source": [
    "Data_Frame_1.head()\n",
    "\n",
    "#list(Data_Frame)[14]\n",
    "\n",
    "#Data_Frame[list(Data_Frame)[14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vq5atLr2eyAC"
   },
   "outputs": [],
   "source": [
    "T = 20\n",
    "T1 = 20\n",
    "\n",
    "#---------------------\n",
    "#T2 = 70   # this is to only consider examples of class 0 that are far from each other\n",
    "#---------------------\n",
    "\n",
    "Ratio_Times = 1     # This is the ratio fof the number of examples in two classes\n",
    "D = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezMMQWEKAOEz"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Data_Frame_1:\n",
    "\n",
    "### DETERMINE the number of conflict versus non-conflict case.\n",
    "\n",
    "#------------------------\n",
    "\n",
    "Y_TEMP_1 = []\n",
    "\n",
    "col_list_1 = list(Data_Frame_1)\n",
    "N_enc_train_1 = (np.array(len(col_list_1)-2)/13).astype(int) # - 5\n",
    "\n",
    "\n",
    "for i_enc in range(N_enc_train_1):    # Number of examples\n",
    "\n",
    "    if Data_Frame_1[col_list_1[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "       \n",
    "       for i_t in range(150):\n",
    "\n",
    "              y = Data_Frame_1[col_list_1[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "              if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "                  Y_TEMP_1.append(y)\n",
    "\n",
    "         \n",
    "Y_TEMP_1 = np.array(Y_TEMP_1)\n",
    "\n",
    "\n",
    "N_ratio_1 = np.sum(Y_TEMP_1)/(len(Y_TEMP_1)-np.sum(Y_TEMP_1))\n",
    "N_ratio_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGBAJy8ogmDL"
   },
   "outputs": [],
   "source": [
    "N_enc_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iAHEiAy5BOW"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_1:\n",
    "\n",
    "### Prepare Data\n",
    "\n",
    "#------------------------\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "col_list_1 = list(Data_Frame_1)\n",
    "\n",
    "for i_enc in range(N_enc_train_1):    # Number of examples\n",
    "\n",
    "    if Data_Frame_1[col_list_1[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "      for i_t in range(150):\n",
    "        \n",
    "        #=============================== Prepare for Future classification case\n",
    "\n",
    "        y = Data_Frame_1[col_list_1[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "        x = np.zeros(shape=(T,D))\n",
    "\n",
    "        if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "           if y==1:\n",
    "\n",
    "              x[:,0] =  Data_Frame_1[col_list_1[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_1[col_list_1[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_1[col_list_1[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_1[col_list_1[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_1[col_list_1[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_1[col_list_1[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_1[col_list_1[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_1[col_list_1[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_1[col_list_1[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_1[col_list_1[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_1[col_list_1[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_1[col_list_1[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X.append(x)\n",
    "              Y.append(y)\n",
    "\n",
    "\n",
    "           elif y==0 and (np.random.uniform(low=0.0,high=1.0)<N_ratio_1*Ratio_Times):  # and i_t<T2:    # this \"and i_t<T2\" is to have only examples far away *****\n",
    "\n",
    "\n",
    "              x[:,0] =  Data_Frame_1[col_list_1[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_1[col_list_1[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_1[col_list_1[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_1[col_list_1[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_1[col_list_1[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_1[col_list_1[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_1[col_list_1[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_1[col_list_1[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_1[col_list_1[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_1[col_list_1[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_1[col_list_1[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_1[col_list_1[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X.append(x)\n",
    "              Y.append(y)\n",
    "\n",
    "\n",
    "        #=================================================================\n",
    "        #-------------------------Delete Variables\n",
    "           del x\n",
    "           del y\n",
    "  \n",
    "        #-------------------------\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_Ad1zWbJ4wh"
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1ZKp1Z4J3Fx"
   },
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWDHl-AWKM13"
   },
   "outputs": [],
   "source": [
    "Y_a_1 = np.array(Y)\n",
    "np.sum(Y_a_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ruyrCeXLY02w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RII2-pL56M1P"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_2 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_2.csv')#, header=None)  \n",
    "Data_Frame_2 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_2.csv')#, header=None)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-gHhugpc2_a"
   },
   "outputs": [],
   "source": [
    "Data_Frame_2.head()\n",
    "\n",
    "#list(Data_Frame_2)[14]\n",
    "\n",
    "#Data_Frame_2[list(Data_Frame_2)[14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKrPDjwPa405"
   },
   "outputs": [],
   "source": [
    "col_list_2 = list(Data_Frame_2)\n",
    "\n",
    "Data_Frame_2[col_list_2[14]][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3zo1Ctf6NxN"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_2:\n",
    "\n",
    "### DETERMINE the number of conflict versus non-conflict case.\n",
    "\n",
    "#------------------------\n",
    "\n",
    "Y_TEMP_2 = []\n",
    "\n",
    "col_list_2 = list(Data_Frame_2)\n",
    "N_enc_train_2 = (np.array(len(col_list_2)-2)/13).astype(int) #- 5\n",
    "\n",
    "\n",
    "for i_enc in range(N_enc_train_2):    # Number of examples\n",
    "\n",
    "    if Data_Frame_2[col_list_2[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "      for i_t in range(150):\n",
    "\n",
    "        y = Data_Frame_2[col_list_2[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "        if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "            Y_TEMP_2.append(y)\n",
    "\n",
    "Y_TEMP_2 = np.array(Y_TEMP_2)\n",
    "\n",
    "\n",
    "N_ratio_2 = np.sum(Y_TEMP_2)/(len(Y_TEMP_2)-np.sum(Y_TEMP_2))\n",
    "N_ratio_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5nkkWbv7kfJ"
   },
   "outputs": [],
   "source": [
    "N_enc_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6TTrfz2VrPu"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_2:\n",
    "\n",
    "### Prepare Data\n",
    "\n",
    "#------------------------\n",
    "\n",
    "col_list_2 = list(Data_Frame_2)\n",
    "\n",
    "for i_enc in range(N_enc_train_2):    # Number of examples\n",
    "\n",
    "    if Data_Frame_2[col_list_2[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "      for i_t in range(150):\n",
    "        \n",
    "        #=============================== Prepare for Future classification case\n",
    "\n",
    "        y = Data_Frame_2[col_list_2[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "        x = np.zeros(shape=(T,D))\n",
    "\n",
    "        if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "           if y==1:\n",
    "\n",
    "              x[:,0] =  Data_Frame_2[col_list_2[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_2[col_list_2[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_2[col_list_2[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_2[col_list_2[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_2[col_list_2[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_2[col_list_2[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_2[col_list_2[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_2[col_list_2[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_2[col_list_2[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_2[col_list_2[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_2[col_list_2[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_2[col_list_2[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X.append(x)\n",
    "              Y.append(y)\n",
    "\n",
    "\n",
    "           elif y==0 and (np.random.uniform(low=0.0,high=1.0)<N_ratio_2*Ratio_Times):  # and i_t<T2:    # this \"and i_t<T2\" is to have only examples far away **********\n",
    "\n",
    "\n",
    "              x[:,0] =  Data_Frame_2[col_list_2[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_2[col_list_2[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_2[col_list_2[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_2[col_list_2[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_2[col_list_2[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_2[col_list_2[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_2[col_list_2[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_2[col_list_2[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_2[col_list_2[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_2[col_list_2[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_2[col_list_2[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_2[col_list_2[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X.append(x)\n",
    "              Y.append(y)\n",
    "\n",
    "\n",
    "        #=================================================================\n",
    "        #-------------------------Delete Variables\n",
    "           del x\n",
    "           del y\n",
    "  \n",
    "        #-------------------------\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HqXs_UGK29p"
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlrtgJJuK2et"
   },
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31ODyakSK18M"
   },
   "outputs": [],
   "source": [
    "Y_a_2 = np.array(Y)\n",
    "np.sum(Y_a_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKOdS0RcZkbp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTSuQOHg8hJx"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Data_Frame_3 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_3.csv')#, header=None)  \n",
    "Data_Frame_3 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_3.csv')#, header=None)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFgAmYcSLUcH"
   },
   "outputs": [],
   "source": [
    "Data_Frame_3.head()\n",
    "\n",
    "#list(Data_Frame_3)[14]\n",
    "\n",
    "#Data_Frame_3[list(Data_Frame_3)[14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jD2Or4yM8gyI"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_3:\n",
    "\n",
    "### DETERMINE the number of conflict versus non-conflict case.\n",
    "\n",
    "#------------------------\n",
    "\n",
    "Y_TEMP_3 = []\n",
    "\n",
    "col_list_3 = list(Data_Frame_3)\n",
    "N_enc_train_3 = (np.array(len(col_list_3)-2)/13).astype(int) #- 5\n",
    "\n",
    "\n",
    "for i_enc in range(N_enc_train_3):    # Number of examples\n",
    "\n",
    "    if Data_Frame_3[col_list_3[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "      for i_t in range(150):\n",
    "\n",
    "        y = Data_Frame_3[col_list_3[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "        if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "            Y_TEMP_3.append(y)\n",
    "    \n",
    "Y_TEMP_3 = np.array(Y_TEMP_3)\n",
    "len(Y_TEMP_3)\n",
    "\n",
    "\n",
    "N_ratio_3 = np.sum(Y_TEMP_3)/(len(Y_TEMP_3)-np.sum(Y_TEMP_3))\n",
    "N_ratio_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIuoS7-c8gXb"
   },
   "outputs": [],
   "source": [
    "N_enc_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Osk0U0uK8f5w"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_3;\n",
    "\n",
    "### Prepare Data\n",
    "\n",
    "#------------------------\n",
    "\n",
    "col_list_3 = list(Data_Frame_3)\n",
    "\n",
    "for i_enc in range(N_enc_train_3):    # Number of examples\n",
    " \n",
    "    if Data_Frame_3[col_list_3[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "       \n",
    "       for i_t in range(150):\n",
    "        \n",
    "          #=============================== Prepare for Future classification case\n",
    "\n",
    "          y = Data_Frame_3[col_list_3[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "          x = np.zeros(shape=(T,D))\n",
    "\n",
    "          if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "             if y==1:\n",
    "\n",
    "                x[:,0] =  Data_Frame_3[col_list_3[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,1] =  Data_Frame_3[col_list_3[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,2] =  Data_Frame_3[col_list_3[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,3] =  Data_Frame_3[col_list_3[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,4] =  Data_Frame_3[col_list_3[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,5] =  Data_Frame_3[col_list_3[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,6] =  Data_Frame_3[col_list_3[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,7] =  Data_Frame_3[col_list_3[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,8] =  Data_Frame_3[col_list_3[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,9] =  Data_Frame_3[col_list_3[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,10] =  Data_Frame_3[col_list_3[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,11] =  Data_Frame_3[col_list_3[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "\n",
    "             elif y==0 and (np.random.uniform(low=0.0,high=1.0)<N_ratio_3*Ratio_Times): # and i_t<T2:    # this \"and i_t<T2\" is to have only examples far away **********\n",
    "\n",
    "\n",
    "                x[:,0] =  Data_Frame_3[col_list_3[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,1] =  Data_Frame_3[col_list_3[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,2] =  Data_Frame_3[col_list_3[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,3] =  Data_Frame_3[col_list_3[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,4] =  Data_Frame_3[col_list_3[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,5] =  Data_Frame_3[col_list_3[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,6] =  Data_Frame_3[col_list_3[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,7] =  Data_Frame_3[col_list_3[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,8] =  Data_Frame_3[col_list_3[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,9] =  Data_Frame_3[col_list_3[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,10] =  Data_Frame_3[col_list_3[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,11] =  Data_Frame_3[col_list_3[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "\n",
    "          #=================================================================\n",
    "          #-------------------------Delete Variables\n",
    "             del x\n",
    "             del y\n",
    "  \n",
    "          #-------------------------\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5hMWmjSM0D5"
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WrCwYTfMztl"
   },
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flROh7CRMzU-"
   },
   "outputs": [],
   "source": [
    "Y_a_3 = np.sum(np.array(Y))\n",
    "Y_a_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlM9NjSpZ05f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYqOA8uF8ed8"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_4 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_4.csv')#, header=None)  \n",
    "Data_Frame_4 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_4.csv')#, header=None)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcVwLXGke0pR"
   },
   "outputs": [],
   "source": [
    "Data_Frame_4.head()\n",
    "\n",
    "#list(Data_Frame_4)[14]\n",
    "\n",
    "#Data_Frame_4[list(Data_Frame_4)[14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABho8WWM8eE5"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_4:\n",
    "\n",
    "### DETERMINE the number of conflict versus non-conflict case.\n",
    "\n",
    "#------------------------\n",
    "\n",
    "Y_TEMP_4 = []\n",
    "\n",
    "col_list_4 = list(Data_Frame_4)\n",
    "N_enc_train_4 = (np.array(len(col_list_4)-2)/13).astype(int) #- 5\n",
    "\n",
    "\n",
    "for i_enc in range(N_enc_train_4):    # Number of examples\n",
    "\n",
    "    if Data_Frame_4[col_list_4[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "       for i_t in range(150):\n",
    "\n",
    "           y = Data_Frame_4[col_list_4[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "           if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "               Y_TEMP_4.append(y)\n",
    "\n",
    "\n",
    "Y_TEMP_4 = np.array(Y_TEMP_4)\n",
    "len(Y_TEMP_4)\n",
    "\n",
    "\n",
    "N_ratio_4 = np.sum(Y_TEMP_4)/(len(Y_TEMP_4)-np.sum(Y_TEMP_4))\n",
    "N_ratio_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuz-NQyHAxhU"
   },
   "outputs": [],
   "source": [
    "N_enc_train_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QOcSALGAxGL"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_4:\n",
    "\n",
    "### Prepare Data\n",
    "\n",
    "#------------------------\n",
    "\n",
    "col_list_4 = list(Data_Frame_4)\n",
    "\n",
    "for i_enc in range(N_enc_train_4):    # Number of examples\n",
    "\n",
    "    if Data_Frame_4[col_list_4[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "       for i_t in range(150):\n",
    "        \n",
    "          #=============================== Prepare for Future classification case\n",
    "\n",
    "          y = Data_Frame_4[col_list_4[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "          x = np.zeros(shape=(T,D))\n",
    "\n",
    "          if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "             if y==1:\n",
    "\n",
    "                x[:,0] =  Data_Frame_4[col_list_4[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,1] =  Data_Frame_4[col_list_4[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,2] =  Data_Frame_4[col_list_4[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,3] =  Data_Frame_4[col_list_4[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,4] =  Data_Frame_4[col_list_4[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,5] =  Data_Frame_4[col_list_4[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,6] =  Data_Frame_4[col_list_4[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,7] =  Data_Frame_4[col_list_4[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,8] =  Data_Frame_4[col_list_4[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,9] =  Data_Frame_4[col_list_4[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,10] =  Data_Frame_4[col_list_4[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,11] =  Data_Frame_4[col_list_4[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "\n",
    "             elif y==0 and (np.random.uniform(low=0.0,high=1.0)<N_ratio_4*Ratio_Times):  # and i_t<T2:    # this \"and i_t<T2\" is to have only examples far away **********\n",
    "\n",
    "\n",
    "                x[:,0] =  Data_Frame_4[col_list_4[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,1] =  Data_Frame_4[col_list_4[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,2] =  Data_Frame_4[col_list_4[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,3] =  Data_Frame_4[col_list_4[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,4] =  Data_Frame_4[col_list_4[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,5] =  Data_Frame_4[col_list_4[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,6] =  Data_Frame_4[col_list_4[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,7] =  Data_Frame_4[col_list_4[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,8] =  Data_Frame_4[col_list_4[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,9] =  Data_Frame_4[col_list_4[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,10] =  Data_Frame_4[col_list_4[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,11] =  Data_Frame_4[col_list_4[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "\n",
    "          #=================================================================\n",
    "          #-------------------------Delete Variables\n",
    "             del x\n",
    "             del y\n",
    "  \n",
    "          #-------------------------\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeYmOe7INxLT"
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSm37b1sNwKL"
   },
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmIDraf4Nvt7"
   },
   "outputs": [],
   "source": [
    "Y_a_4 = np.sum(np.array(Y))\n",
    "Y_a_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkeR2U3UNvOW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rn_0iIyZ9Jw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZMkOQxUAwtB"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_5 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_5.csv')#, header=None)  \n",
    "Data_Frame_5 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_5.csv')#, header=None)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdNybLNEflHG"
   },
   "outputs": [],
   "source": [
    "Data_Frame_5.head()\n",
    "\n",
    "#list(Data_Frame_5)[14]\n",
    "\n",
    "#Data_Frame_5[list(Data_Frame_5)[14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knL5yyB5AwSX"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_5:\n",
    "\n",
    "### DETERMINE the number of conflict versus non-conflict case.\n",
    "\n",
    "#------------------------\n",
    "\n",
    "Y_TEMP_5 = []\n",
    "\n",
    "col_list_5 = list(Data_Frame_5)\n",
    "N_enc_train_5 = (np.array(len(col_list_5)-2)/13).astype(int) #- 5\n",
    "\n",
    "\n",
    "for i_enc in range(N_enc_train_5):    # Number of examples\n",
    "\n",
    "    if Data_Frame_5[col_list_5[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "       \n",
    "       for i_t in range(150):\n",
    "\n",
    "           y = Data_Frame_5[col_list_5[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "           if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "               Y_TEMP_5.append(y)\n",
    "\n",
    "    \n",
    "Y_TEMP_5 = np.array(Y_TEMP_5)\n",
    "len(Y_TEMP_5)\n",
    "\n",
    "\n",
    "N_ratio_5 = np.sum(Y_TEMP_5)/(len(Y_TEMP_5)-np.sum(Y_TEMP_5))\n",
    "N_ratio_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WT8d1SwFAv4i"
   },
   "outputs": [],
   "source": [
    "N_enc_train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7ws9ZumAvaL"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_5:\n",
    "\n",
    "### Prepare Data\n",
    "\n",
    "#------------------------\n",
    "\n",
    "col_list_5 = list(Data_Frame_5)\n",
    "\n",
    "for i_enc in range(N_enc_train_5):    # Number of examples\n",
    "\n",
    "    if Data_Frame_5[col_list_5[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "       for i_t in range(150):\n",
    "        \n",
    "          #=============================== Prepare for Future classification case\n",
    "\n",
    "          y = Data_Frame_5[col_list_5[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "          x = np.zeros(shape=(T,D))\n",
    "\n",
    "          if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "             if y==1:\n",
    "\n",
    "                x[:,0] =  Data_Frame_5[col_list_5[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,1] =  Data_Frame_5[col_list_5[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,2] =  Data_Frame_5[col_list_5[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,3] =  Data_Frame_5[col_list_5[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,4] =  Data_Frame_5[col_list_5[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,5] =  Data_Frame_5[col_list_5[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,6] =  Data_Frame_5[col_list_5[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,7] =  Data_Frame_5[col_list_5[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,8] =  Data_Frame_5[col_list_5[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,9] =  Data_Frame_5[col_list_5[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,10] =  Data_Frame_5[col_list_5[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,11] =  Data_Frame_5[col_list_5[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "\n",
    "             elif y==0 and (np.random.uniform(low=0.0,high=1.0)<N_ratio_5*Ratio_Times):  # and i_t<T2:    # this \"and i_t<T2\" is to have only examples far away **********\n",
    "\n",
    "\n",
    "                x[:,0] =  Data_Frame_5[col_list_5[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,1] =  Data_Frame_5[col_list_5[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,2] =  Data_Frame_5[col_list_5[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,3] =  Data_Frame_5[col_list_5[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,4] =  Data_Frame_5[col_list_5[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,5] =  Data_Frame_5[col_list_5[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,6] =  Data_Frame_5[col_list_5[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,7] =  Data_Frame_5[col_list_5[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,8] =  Data_Frame_5[col_list_5[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,9] =  Data_Frame_5[col_list_5[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,10] =  Data_Frame_5[col_list_5[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,11] =  Data_Frame_5[col_list_5[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "\n",
    "          #=================================================================\n",
    "          #-------------------------Delete Variables\n",
    "             del x\n",
    "             del y\n",
    "  \n",
    "          #-------------------------\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAiPOMhWPTH5"
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRq1Id90PSsP"
   },
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyIEPnFQPSPn"
   },
   "outputs": [],
   "source": [
    "Y_a_5 = np.sum(np.array(Y))\n",
    "Y_a_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bsgguZUPRyT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdSoHOTpaFcY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8UuloviC04d"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_6 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_6.csv')#, header=None)  \n",
    "Data_Frame_6 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_6.csv')#, header=None)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRbPRZUWgQtF"
   },
   "outputs": [],
   "source": [
    "Data_Frame_6.head()\n",
    "\n",
    "#list(Data_Frame_6)[14]\n",
    "\n",
    "#Data_Frame_6[list(Data_Frame_6)[14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZhQw1CaC0GW"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_6:\n",
    "\n",
    "### DETERMINE the number of conflict versus non-conflict case.\n",
    "\n",
    "#------------------------\n",
    "\n",
    "Y_TEMP_6 = []\n",
    "\n",
    "col_list_6 = list(Data_Frame_6)\n",
    "N_enc_train_6 = (np.array(len(col_list_6)-2)/13).astype(int) #- 5\n",
    "\n",
    "\n",
    "for i_enc in range(N_enc_train_6):    # Number of examples\n",
    "\n",
    "    if Data_Frame_6[col_list_6[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "       for i_t in range(150):\n",
    "\n",
    "          y = Data_Frame_6[col_list_6[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "          if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "              Y_TEMP_6.append(y)\n",
    "\n",
    "    \n",
    "Y_TEMP_6 = np.array(Y_TEMP_6)\n",
    "len(Y_TEMP_6)\n",
    "\n",
    "\n",
    "N_ratio_6 = np.sum(Y_TEMP_6)/(len(Y_TEMP_6)-np.sum(Y_TEMP_6))\n",
    "N_ratio_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4h0h5s2mCzu7"
   },
   "outputs": [],
   "source": [
    "N_enc_train_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DOAdRxCCzWJ"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_6:\n",
    "\n",
    "### Prepare Data\n",
    "\n",
    "#------------------------\n",
    "\n",
    "col_list_6 = list(Data_Frame_6)\n",
    "\n",
    "for i_enc in range(N_enc_train_6):    # Number of examples\n",
    "\n",
    "    if Data_Frame_6[col_list_6[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "       for i_t in range(150):\n",
    "        \n",
    "          #=============================== Prepare for Future classification case\n",
    "\n",
    "          y = Data_Frame_6[col_list_6[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "          x = np.zeros(shape=(T,D))\n",
    "\n",
    "          if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "             if y==1:\n",
    "\n",
    "                x[:,0] =  Data_Frame_6[col_list_6[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,1] =  Data_Frame_6[col_list_6[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,2] =  Data_Frame_6[col_list_6[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,3] =  Data_Frame_6[col_list_6[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,4] =  Data_Frame_6[col_list_6[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,5] =  Data_Frame_6[col_list_6[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,6] =  Data_Frame_6[col_list_6[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,7] =  Data_Frame_6[col_list_6[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,8] =  Data_Frame_6[col_list_6[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,9] =  Data_Frame_6[col_list_6[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,10] =  Data_Frame_6[col_list_6[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,11] =  Data_Frame_6[col_list_6[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "\n",
    "             elif y==0 and (np.random.uniform(low=0.0,high=1.0)<N_ratio_6*Ratio_Times):  # and i_t<T2:    # this \"and i_t<T2\" is to have only examples far away **********\n",
    "\n",
    "\n",
    "                x[:,0] =  Data_Frame_6[col_list_6[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,1] =  Data_Frame_6[col_list_6[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,2] =  Data_Frame_6[col_list_6[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,3] =  Data_Frame_6[col_list_6[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,4] =  Data_Frame_6[col_list_6[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,5] =  Data_Frame_6[col_list_6[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,6] =  Data_Frame_6[col_list_6[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,7] =  Data_Frame_6[col_list_6[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,8] =  Data_Frame_6[col_list_6[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,9] =  Data_Frame_6[col_list_6[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,10] =  Data_Frame_6[col_list_6[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,11] =  Data_Frame_6[col_list_6[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "\n",
    "          #=================================================================\n",
    "          #-------------------------Delete Variables\n",
    "             del x\n",
    "             del y\n",
    "  \n",
    "          #-------------------------\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1dixHm9P6Xl"
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLIjLkieP57n"
   },
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36S59DVFP5i_"
   },
   "outputs": [],
   "source": [
    "Y_a_6 = np.sum(np.array(Y))\n",
    "Y_a_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qKxlmHZP5JG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IjfaIUEaOVZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMMwa8OYCy9V"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_7 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_7.csv')#, header=None)  \n",
    "Data_Frame_7 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_7.csv')#, header=None)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5DyTDggQOji"
   },
   "outputs": [],
   "source": [
    "Data_Frame_7.head()\n",
    "\n",
    "#list(Data_Frame_7)[14]\n",
    "\n",
    "#Data_Frame_7[list(Data_Frame_7)[14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpB3g4LBCyeN"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_7:\n",
    "\n",
    "### DETERMINE the number of conflict versus non-conflict case.\n",
    "\n",
    "#------------------------\n",
    "\n",
    "Y_TEMP_7 = []\n",
    "\n",
    "col_list_7 = list(Data_Frame_7)\n",
    "N_enc_train_7 = (np.array(len(col_list_7)-2)/13).astype(int) #- 5\n",
    "\n",
    "\n",
    "for i_enc in range(N_enc_train_7):    # Number of examples\n",
    "\n",
    "    if Data_Frame_7[col_list_7[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "       for i_t in range(150):\n",
    "\n",
    "          y = Data_Frame_7[col_list_7[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "          if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "              Y_TEMP_7.append(y)\n",
    "\n",
    "\n",
    "Y_TEMP_7 = np.array(Y_TEMP_7)\n",
    "len(Y_TEMP_7)\n",
    "\n",
    "\n",
    "N_ratio_7 = np.sum(Y_TEMP_7)/(len(Y_TEMP_7)-np.sum(Y_TEMP_7))\n",
    "N_ratio_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1cWBrpqCyDH"
   },
   "outputs": [],
   "source": [
    "N_enc_train_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pl-KAAgmCxlL"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_7:\n",
    "\n",
    "### Prepare Data\n",
    "\n",
    "#------------------------\n",
    "\n",
    "col_list_7 = list(Data_Frame_7)\n",
    "\n",
    "for i_enc in range(N_enc_train_7):    # Number of examples\n",
    "\n",
    "    if Data_Frame_7[col_list_7[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "       \n",
    "       for i_t in range(150):\n",
    "        \n",
    "          #=============================== Prepare for Future classification case\n",
    "\n",
    "          y = Data_Frame_7[col_list_7[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "          x = np.zeros(shape=(T,D))\n",
    "\n",
    "          if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "             if y==1:\n",
    "\n",
    "                x[:,0] =  Data_Frame_7[col_list_7[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,1] =  Data_Frame_7[col_list_7[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,2] =  Data_Frame_7[col_list_7[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,3] =  Data_Frame_7[col_list_7[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,4] =  Data_Frame_7[col_list_7[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,5] =  Data_Frame_7[col_list_7[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,6] =  Data_Frame_7[col_list_7[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,7] =  Data_Frame_7[col_list_7[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,8] =  Data_Frame_7[col_list_7[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,9] =  Data_Frame_7[col_list_7[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,10] =  Data_Frame_7[col_list_7[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,11] =  Data_Frame_7[col_list_7[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "\n",
    "             elif y==0 and (np.random.uniform(low=0.0,high=1.0)<N_ratio_7*Ratio_Times):  # and i_t<T2:    # this \"and i_t<T2\" is to have only examples far away **********\n",
    "\n",
    "\n",
    "                x[:,0] =  Data_Frame_7[col_list_7[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,1] =  Data_Frame_7[col_list_7[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,2] =  Data_Frame_7[col_list_7[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,3] =  Data_Frame_7[col_list_7[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,4] =  Data_Frame_7[col_list_7[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,5] =  Data_Frame_7[col_list_7[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,6] =  Data_Frame_7[col_list_7[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,7] =  Data_Frame_7[col_list_7[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,8] =  Data_Frame_7[col_list_7[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,9] =  Data_Frame_7[col_list_7[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,10] =  Data_Frame_7[col_list_7[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "                x[:,11] =  Data_Frame_7[col_list_7[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "\n",
    "          #=================================================================\n",
    "          #-------------------------Delete Variables\n",
    "             del x\n",
    "             del y\n",
    "  \n",
    "          #-------------------------\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hi444qB0Q1iV"
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYhMG9vfQ1GY"
   },
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcXHYxN6Q0rt"
   },
   "outputs": [],
   "source": [
    "Y_a_7 = np.sum(np.array(Y))\n",
    "Y_a_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8XwAKG6Q0O1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFlFbafBaZO1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBwKE5sOCxMr"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_8 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_8.csv')#, header=None)  \n",
    "Data_Frame_8 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_8.csv')#, header=None)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rfnP2xhRDKd"
   },
   "outputs": [],
   "source": [
    "Data_Frame_8.head()\n",
    "\n",
    "#list(Data_Frame_8)[14]\n",
    "\n",
    "#Data_Frame_8[list(Data_Frame_8)[14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MEeHUMYCwvb"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_8:\n",
    "\n",
    "### DETERMINE the number of conflict versus non-conflict case.\n",
    "\n",
    "#------------------------\n",
    "\n",
    "Y_TEMP_8 = []\n",
    "\n",
    "col_list_8 = list(Data_Frame_8)\n",
    "N_enc_train_8 = (np.array(len(col_list_8)-2)/13).astype(int) #- 5\n",
    "\n",
    "\n",
    "for i_enc in range(N_enc_train_8):    # Number of examples\n",
    "\n",
    "    if Data_Frame_8[col_list_8[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "       for i_t in range(150):\n",
    "\n",
    "          y = Data_Frame_8[col_list_8[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "          if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "              Y_TEMP_8.append(y)\n",
    "\n",
    "    \n",
    "Y_TEMP_8 = np.array(Y_TEMP_8)\n",
    "len(Y_TEMP_8)\n",
    "\n",
    "\n",
    "N_ratio_8 = np.sum(Y_TEMP_8)/(len(Y_TEMP_8)-np.sum(Y_TEMP_8))\n",
    "N_ratio_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQMGp79nCwXh"
   },
   "outputs": [],
   "source": [
    "N_enc_train_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neCD8cB0AvAy"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_8:\n",
    "\n",
    "### Prepare Data\n",
    "\n",
    "#------------------------\n",
    "\n",
    "col_list_8 = list(Data_Frame_8)\n",
    "\n",
    "for i_enc in range(N_enc_train_8):    # Number of examples\n",
    "\n",
    "    if Data_Frame_8[col_list_8[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "      for i_t in range(150):\n",
    "        \n",
    "        #=============================== Prepare for Future classification case\n",
    "\n",
    "        y = Data_Frame_8[col_list_8[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "        x = np.zeros(shape=(T,D))\n",
    "\n",
    "        if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "           if y==1:\n",
    "\n",
    "              x[:,0] =  Data_Frame_8[col_list_8[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_8[col_list_8[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_8[col_list_8[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_8[col_list_8[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_8[col_list_8[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_8[col_list_8[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_8[col_list_8[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_8[col_list_8[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_8[col_list_8[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_8[col_list_8[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_8[col_list_8[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_8[col_list_8[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X.append(x)\n",
    "              Y.append(y)\n",
    "\n",
    "\n",
    "           elif y==0 and (np.random.uniform(low=0.0,high=1.0)<N_ratio_8*Ratio_Times):  # and i_t<T2:    # this \"and i_t<T2\" is to have only examples far away **********\n",
    "\n",
    "\n",
    "              x[:,0] =  Data_Frame_8[col_list_8[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_8[col_list_8[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_8[col_list_8[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_8[col_list_8[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_8[col_list_8[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_8[col_list_8[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_8[col_list_8[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_8[col_list_8[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_8[col_list_8[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_8[col_list_8[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_8[col_list_8[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_8[col_list_8[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X.append(x)\n",
    "              Y.append(y)\n",
    "\n",
    "\n",
    "        #=================================================================\n",
    "        #-------------------------Delete Variables\n",
    "           del x\n",
    "           del y\n",
    "  \n",
    "        #-------------------------\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUUclDmLRo_d"
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVaFUeOARohY"
   },
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K05Kpi8xRoFn"
   },
   "outputs": [],
   "source": [
    "Y_a_8 = np.sum(np.array(Y))\n",
    "Y_a_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j420wpXcRnlL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTRK9zuGajm8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLqdVo7-IgYK"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_9 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_9.csv')#, header=None)  \n",
    "Data_Frame_9 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_9.csv')#, header=None)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW6tSz-nR2nn"
   },
   "outputs": [],
   "source": [
    "Data_Frame_9.head()\n",
    "\n",
    "#list(Data_Frame_9)[14]\n",
    "\n",
    "#Data_Frame_9[list(Data_Frame_9)[14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9lrBlgtIf_9"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_9:\n",
    "\n",
    "### DETERMINE the number of conflict versus non-conflict case.\n",
    "\n",
    "#------------------------\n",
    "\n",
    "Y_TEMP_9 = []\n",
    "\n",
    "\n",
    "col_list_9 = list(Data_Frame_9)\n",
    "N_enc_train_9 = (np.array(len(col_list_9)-2)/13).astype(int) #- 5\n",
    "\n",
    "\n",
    "for i_enc in range(N_enc_train_9):    # Number of examples\n",
    "\n",
    "    if Data_Frame_9[col_list_9[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "      for i_t in range(150):\n",
    "\n",
    "        y = Data_Frame_9[col_list_9[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "        if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "            Y_TEMP_9.append(y)\n",
    "\n",
    "\n",
    "Y_TEMP_9 = np.array(Y_TEMP_9)\n",
    "len(Y_TEMP_9)\n",
    "\n",
    "\n",
    "N_ratio_9 = np.sum(Y_TEMP_9)/(len(Y_TEMP_9)-np.sum(Y_TEMP_9))\n",
    "N_ratio_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9EhAGeuIflw"
   },
   "outputs": [],
   "source": [
    "N_enc_train_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPr459Y9IfJg"
   },
   "outputs": [],
   "source": [
    "### Data_Frame_9:\n",
    "\n",
    "### Prepare Data\n",
    "\n",
    "#------------------------\n",
    "\n",
    "col_list_9 = list(Data_Frame_9)\n",
    "\n",
    "for i_enc in range(N_enc_train_9):    # Number of examples\n",
    "\n",
    "    if Data_Frame_9[col_list_9[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "      for i_t in range(150):\n",
    "        \n",
    "        #=============================== Prepare for Future classification case\n",
    "\n",
    "        y = Data_Frame_9[col_list_9[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "        x = np.zeros(shape=(T,D))\n",
    "\n",
    "        if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "           if y==1:\n",
    "\n",
    "              x[:,0] =  Data_Frame_9[col_list_9[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_9[col_list_9[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_9[col_list_9[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_9[col_list_9[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_9[col_list_9[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_9[col_list_9[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_9[col_list_9[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_9[col_list_9[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_9[col_list_9[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_9[col_list_9[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_9[col_list_9[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_9[col_list_9[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X.append(x)\n",
    "              Y.append(y)\n",
    "\n",
    "\n",
    "           elif y==0 and (np.random.uniform(low=0.0,high=1.0)<N_ratio_9*Ratio_Times):  # and i_t<T2:    # this \"and i_t<T2\" is to have only examples far away **********\n",
    "\n",
    "\n",
    "              x[:,0] =  Data_Frame_9[col_list_9[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_9[col_list_9[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_9[col_list_9[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_9[col_list_9[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_9[col_list_9[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_9[col_list_9[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_9[col_list_9[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_9[col_list_9[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_9[col_list_9[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_9[col_list_9[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_9[col_list_9[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_9[col_list_9[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X.append(x)\n",
    "              Y.append(y)\n",
    "\n",
    "\n",
    "        #=================================================================\n",
    "        #-------------------------Delete Variables\n",
    "           del x\n",
    "           del y\n",
    "  \n",
    "        #-------------------------\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhWPSQFPSTxi"
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1KB36vGSTSM"
   },
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUWewFRxSS7W"
   },
   "outputs": [],
   "source": [
    "Y_a_9 = np.sum(np.array(Y))\n",
    "Y_a_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuV9EmVvSSir"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWO0iJ8Ba4Qr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDqgkF-hIchK"
   },
   "outputs": [],
   "source": [
    "### Convert list to numpy array to feed into RNN\n",
    "\n",
    "X_train = np.array(X)\n",
    "Y_train = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOgRhvo-IcGs"
   },
   "outputs": [],
   "source": [
    "np.sum(Y_train)      ## Number of examples for class 1 (NMAC class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMi6abQ8IbqK"
   },
   "outputs": [],
   "source": [
    "len(Y_train)-np.sum(Y_train)    ## Number of examples for class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OadEphBB8drk"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_X = pd.DataFrame(X_train)\n",
    "#Data_Frame_Y = pd.DataFrame(Y_train)\n",
    "\n",
    "#Data_Frame_X.to_csv('/content/drive/My Drive/X_train.csv')\n",
    "#Data_Frame_Y.to_csv('/content/drive/My Drive/Y_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTRexknGQ97n"
   },
   "outputs": [],
   "source": [
    "### Delete those variables that are not needed any more to use less RAM\n",
    "\n",
    "del Data_Frame_1\n",
    "del Data_Frame_2\n",
    "del Data_Frame_3\n",
    "del Data_Frame_4\n",
    "del Data_Frame_5\n",
    "del Data_Frame_6\n",
    "del Data_Frame_7\n",
    "del Data_Frame_8\n",
    "del Data_Frame_9\n",
    "\n",
    "del Y_TEMP_1\n",
    "del Y_TEMP_2\n",
    "del Y_TEMP_3\n",
    "del Y_TEMP_4\n",
    "del Y_TEMP_5\n",
    "del Y_TEMP_6\n",
    "del Y_TEMP_7\n",
    "del Y_TEMP_8\n",
    "del Y_TEMP_9\n",
    "\n",
    "del col_list_1\n",
    "del col_list_2\n",
    "del col_list_3\n",
    "del col_list_4\n",
    "del col_list_5\n",
    "del col_list_6\n",
    "del col_list_7\n",
    "del col_list_8\n",
    "del col_list_9\n",
    "\n",
    "del N_enc_train_1\n",
    "del N_enc_train_2\n",
    "del N_enc_train_3\n",
    "del N_enc_train_4\n",
    "del N_enc_train_5\n",
    "del N_enc_train_6\n",
    "del N_enc_train_7\n",
    "del N_enc_train_8\n",
    "del N_enc_train_9\n",
    "\n",
    "\n",
    "del N_ratio_1\n",
    "del N_ratio_2\n",
    "del N_ratio_3\n",
    "del N_ratio_4\n",
    "del N_ratio_5\n",
    "del N_ratio_6\n",
    "del N_ratio_7\n",
    "del N_ratio_8\n",
    "del N_ratio_9\n",
    "\n",
    "\n",
    "del Y_a_1\n",
    "del Y_a_2\n",
    "del Y_a_3\n",
    "del Y_a_4\n",
    "del Y_a_5\n",
    "del Y_a_6\n",
    "del Y_a_7\n",
    "del Y_a_8\n",
    "del Y_a_9\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcXS3ew2aAnN"
   },
   "outputs": [],
   "source": [
    "np.sum(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3bKZ_X7aABT"
   },
   "outputs": [],
   "source": [
    "len(Y_train)-np.sum(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIqTL48KICm3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fle76ODU3-lO"
   },
   "outputs": [],
   "source": [
    "# Now Train a Deep LSTM with Global Max Pooling\n",
    "#inputs = np.expand_dims(X, -1)\n",
    "inputs = X_train\n",
    "\n",
    "# make the RNN\n",
    "i = Input(shape=(T, D))\n",
    "\n",
    "# method 1\n",
    "#x = LSTM(20)(i)\n",
    "\n",
    "\n",
    "#----------------------------------- Tanh activation is default\n",
    "\n",
    "#x = LSTM(20, return_sequences= True)(i) \n",
    "#x = LSTM(20, return_sequences= True)(x) \n",
    "#x = LSTM(20, return_sequences= True)(x) \n",
    "#x = LSTM(20, return_sequences= True)(x) \n",
    "#x = LSTM(5, return_sequences= True)(x) \n",
    "#x = LSTM(5, return_sequences= True)(x) \n",
    "\n",
    "\n",
    "#x = GlobalMaxPool1D()(x)\n",
    "\n",
    "\n",
    "#x = Dense(1, activation='sigmoid')(x)\n",
    "#model = Model(i, x)\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "#----------------------------------- Sequential approach\n",
    "\n",
    "layer_1 = keras.layers.LSTM(25, activation='sigmoid')   #, return_sequences= True) \n",
    "#layer_2 = keras.layers.LSTM(20, return_sequences= True)\n",
    "#layer_3 = keras.layers.LSTM(20, return_sequences= True)\n",
    "#layer_4 = keras.layers.LSTM(20, return_sequences= True)\n",
    "\n",
    "#layer_5 = keras.layers.GlobalMaxPool1D()\n",
    "layer_6 = keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "#model = keras.Sequential([i, layer_1, layer_2, layer_3, layer_4, layer_5, layer_6])\n",
    "\n",
    "model = keras.Sequential([i, layer_1, layer_6])\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "#----------------------------------- Sequential approach\n",
    "\n",
    "#layer_1 = keras.layers.LSTM(20, return_sequences= True, activation='sigmoid') \n",
    "#layer_2 = keras.layers.LSTM(20, return_sequences= True, activation='sigmoid')\n",
    "#layer_3 = keras.layers.LSTM(20, return_sequences= True, activation='sigmoid')\n",
    "#layer_4 = keras.layers.LSTM(20, return_sequences= True, activation='sigmoid')\n",
    "\n",
    "#layer_5 = keras.layers.GlobalMaxPool1D()\n",
    "#layer_6 = keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "#model = keras.Sequential([i, layer_1, layer_2, layer_3, layer_4, layer_5, layer_6])\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "\n",
    "#----------------------------------- Sigmoid activation\n",
    "\n",
    "#x = LSTM(15, return_sequences= True, activation='sigmoid')(i)\n",
    "#x = LSTM(15, return_sequences= True, activation='sigmoid')(x)\n",
    "#x = LSTM(15, return_sequences= True, activation='sigmoid')(x)\n",
    "#x = LSTM(15, return_sequences= True, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "#x = GlobalMaxPool1D()(x)\n",
    "\n",
    "\n",
    "#x = Dense(1, activation='sigmoid')(x)\n",
    "#model = Model(i, x)\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "#----------------------------------- Sigmoid activation\n",
    "\n",
    "#x = LSTM(15, return_sequences= True, activation='relu')(i)\n",
    "#x = LSTM(15, return_sequences= True, activation='relu')(x)\n",
    "#x = LSTM(15, return_sequences= True, activation='relu')(x)\n",
    "#x = LSTM(15, return_sequences= True, activation='relu')(x)\n",
    "\n",
    "\n",
    "#x = GlobalMaxPool1D()(x)\n",
    "\n",
    "\n",
    "#x = Dense(1, activation='sigmoid')(x)\n",
    "#model = Model(i, x)\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------ Try this block to have the accuracy with a threshold 0.5\n",
    "\n",
    "#tf.keras.metrics.BinaryAccuracy(\n",
    "#    name=\"binary_accuracy\", dtype=None, threshold=0.5\n",
    "#)\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0003),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "#model.compile(\n",
    "#  loss='binary_crossentropy',\n",
    "#  # optimizer='rmsprop',\n",
    "##   optimizer='adam',\n",
    "#   optimizer=Adam(lr=0.01),\n",
    "#   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "#  metrics=['accuracy'],\n",
    "#)\n",
    "\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=50,\n",
    "  validation_split=0.1,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djfbJKw0u6yD"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0002),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "#model.compile(\n",
    "#  loss='binary_crossentropy',\n",
    "#  # optimizer='rmsprop',\n",
    "##   optimizer='adam',\n",
    "#   optimizer=Adam(lr=0.01),\n",
    "#   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "#  metrics=['accuracy'],\n",
    "#)\n",
    "\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=10,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlZc_KKgErXR"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "#model.compile(\n",
    "#  loss='binary_crossentropy',\n",
    "#  # optimizer='rmsprop',\n",
    "##   optimizer='adam',\n",
    "#   optimizer=Adam(lr=0.01),\n",
    "#   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "#  metrics=['accuracy'],\n",
    "#)\n",
    "\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=10,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLU9JuNbGeTU"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "#model.compile(\n",
    "#  loss='binary_crossentropy',\n",
    "#  # optimizer='rmsprop',\n",
    "##   optimizer='adam',\n",
    "#   optimizer=Adam(lr=0.01),\n",
    "#   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "#  metrics=['accuracy'],\n",
    "#)\n",
    "\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-9YLpTSIs6h"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "#model.compile(\n",
    "#  loss='binary_crossentropy',\n",
    "#  # optimizer='rmsprop',\n",
    "##   optimizer='adam',\n",
    "#   optimizer=Adam(lr=0.01),\n",
    "#   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "#  metrics=['accuracy'],\n",
    "#)\n",
    "\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRxKemovKeYX"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "#model.compile(\n",
    "#  loss='binary_crossentropy',\n",
    "#  # optimizer='rmsprop',\n",
    "##   optimizer='adam',\n",
    "#   optimizer=Adam(lr=0.01),\n",
    "#   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "#  metrics=['accuracy'],\n",
    "#)\n",
    "\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zz9hewP8M0Z7"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "#model.compile(\n",
    "#  loss='binary_crossentropy',\n",
    "#  # optimizer='rmsprop',\n",
    "##   optimizer='adam',\n",
    "#   optimizer=Adam(lr=0.01),\n",
    "#   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "#  metrics=['accuracy'],\n",
    "#)\n",
    "\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.1,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nHEMOe9OqGK"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCswXjsoQcCE"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0sG_6tnSCRz"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.1,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqLuuhGjU-cB"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.1,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJggR_VkX9R6"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_BfZgVdZoU_"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00008),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rU6zuXstbXaR"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00006),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SR2onALuc73I"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00004),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a98tb70lhhCG"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00003),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qlp8gKBqjHTn"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.3,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5b2yBTZk6eS"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "    #optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.000005),\n",
    "   #optimizer=SGD(lr=0.000001, momentum=0.6),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=3,\n",
    "  validation_split=0.2,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Az2B4yGiEdt7"
   },
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "plt.plot(r1.history['loss'], label='loss')\n",
    "plt.plot(r1.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.title('Loss', fontsize=15)\n",
    "\n",
    "plt.savefig('Loss_20sec_Noisy_Far_0_Class.png', dpi=220, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcLnmrcmEfQ5"
   },
   "outputs": [],
   "source": [
    "## Plot the accuracy too\n",
    "\n",
    "#------------------------------------------Use this block if Keras accuracy used above\n",
    "# Plot the accuracy too\n",
    "plt.plot(r1.history['binary_accuracy'], label='acc')\n",
    "plt.plot(r1.history['val_binary_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.title('Accuracy', fontsize=15)\n",
    "\n",
    "plt.savefig('Accuracy_20sec_Noisy_Far_0_Class.png', dpi=220, bbox_inches='tight')\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "#----------------------------------------------------\n",
    "#plt.plot(r.history['accuracy'], label='acc')\n",
    "#plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "#plt.legend()\n",
    "\n",
    "#plt.savefig('Conflict_Class_Accuracy_Predict_20sec.png', dpi=220, bbox_inches='tight')\n",
    "#---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLa1XUtmUGJx"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0003),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=50,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWb4I-qi-3yA"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0003),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=50,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MetDal08CcZD"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0003),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=20,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVzrY6uqDrO4"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0003),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=10,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHCnDFlgiL0I"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0002),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=10,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_XYnacyjwox"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0001),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=10,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkuPIlhglVs8"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00009),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=10,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8G8XXyvm8bh"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00007),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeHMkkHcoBvj"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00006),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdbvbAGDqBHa"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00005),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEZKzW1gq0oI"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00002),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6g8v_Kdfrrt5"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.000007),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hj9uXDJVsiwW"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.000001),      ## ?????\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=5,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R55Hs_Q6GRf7"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/Pretrained_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_54k7hMyHHmd"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/content/drive/My Drive/Pretrained_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAg6q7KGGMEV"
   },
   "outputs": [],
   "source": [
    "### Further Train the Network with a smaller learning rate:\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   #optimizer=Adam(lr=0.0001),      ## ?????\n",
    "   optimizer=SGD(lr=0.0001, momentum=0.1),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r1 = model.fit(\n",
    "  inputs, Y_train,\n",
    "  epochs=20,\n",
    "  validation_split=0.1,        ## ?????\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5hmBAQKu-8b"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/Pretrained_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUs1tT23b_-t"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5u3_mYkfNC7"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/Pretrained_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIb6JUpLjbFq"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/content/drive/My Drive/Pretrained_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Rwvgt-woVKf"
   },
   "outputs": [],
   "source": [
    "#layer_6.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3mViwLDp-Nd"
   },
   "outputs": [],
   "source": [
    "#layer_6.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bX1fahhVUCyo"
   },
   "outputs": [],
   "source": [
    "### Prepare a data set including misclassified/false detection examples to retrain the RNN \n",
    "\n",
    "Y_train_Class = Y_train.flatten()\n",
    "\n",
    "outputs_train_1 = model.predict(X_train)\n",
    "outputs_train = outputs_train_1.flatten() \n",
    "\n",
    "outputs_train_Class = (outputs_train>0.5)*1\n",
    "\n",
    "mis_classed = outputs_train_Class != Y_train_Class    #  == or !=   ????\n",
    "\n",
    "XX_train = np.zeros(shape=(np.sum(mis_classed), T, D))\n",
    "YY_train = np.zeros(np.sum(mis_classed))\n",
    "\n",
    "i_xx = 0\n",
    "for i_m in range(len(mis_classed)):\n",
    "\n",
    "  if (mis_classed[i_m] == 1) and (Y_train_Class[i_m] == 1):\n",
    "\n",
    "    XX_train[i_xx] = X_train[i_m]\n",
    "    YY_train[i_xx] = Y_train_Class[i_m]\n",
    "\n",
    "    i_xx += 1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9Eu-Vjen4X8"
   },
   "outputs": [],
   "source": [
    "YY_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtThaoWdFLRC"
   },
   "outputs": [],
   "source": [
    "XX_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGWZin7QczBE"
   },
   "outputs": [],
   "source": [
    "### Freeze all the layers but the last\n",
    "\n",
    "layer_1.trainable = False\n",
    "layer_2.trainable = False\n",
    "layer_3.trainable = False\n",
    "layer_4.trainable = False\n",
    "layer_5.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olDb39KnpbpW"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.00002),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r2 = model.fit(\n",
    "  XX_train, YY_train,\n",
    "  epochs=10,\n",
    "  validation_split=0.3,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvEg-Bl9HqWi"
   },
   "outputs": [],
   "source": [
    "# Retrain the whole network with a small training rate\n",
    "\n",
    "layer_1.trainable = True\n",
    "layer_2.trainable = True\n",
    "layer_3.trainable = True\n",
    "layer_4.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1H6gjpGUZdz"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "#   optimizer='adam',\n",
    "   optimizer=Adam(lr=0.0000001),\n",
    "   #optimizer=SGD(lr=0.1, momentum=0.9),\n",
    "  #metrics=['accuracy'],\n",
    "  metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)],\n",
    ")\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "# train the RNN\n",
    "r3 = model.fit(\n",
    "  XX_train, YY_train,         # Set the data set right\n",
    "  epochs=10,\n",
    "  validation_split=0.1,\n",
    "  #validation_split=0.5,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f57a9U_4Jmm"
   },
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Nzo0woY5x6O"
   },
   "outputs": [],
   "source": [
    "YY_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEykAuTQVJpI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51rVHivlEDoy"
   },
   "outputs": [],
   "source": [
    "#new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbFFr2rOyA1w"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_10 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_10.csv')#, header=None)  \n",
    "\n",
    "Data_Frame_10 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_10.csv')#, header=None)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHksv2pKyLb5"
   },
   "outputs": [],
   "source": [
    "Data_Frame_10.head()\n",
    "\n",
    "#list(Data_Frame_10)[14]\n",
    "\n",
    "#Data_Frame_10[list(Data_Frame_10)[14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zab73DqCyPcC"
   },
   "outputs": [],
   "source": [
    "### Data_Franme_10:\n",
    "\n",
    "### DETERMINE the number of conflict versus non-conflict case.\n",
    "\n",
    "#------------------------\n",
    "\n",
    "#T = 15\n",
    "#T1 = 15\n",
    "#D = 12\n",
    "\n",
    "\n",
    "Y_TEMP_10 = []\n",
    "\n",
    "\n",
    "col_list_10 = list(Data_Frame_10)\n",
    "N_enc_train_10 = (np.array(len(col_list_10)-2)/13).astype(int) #- 5\n",
    "\n",
    "\n",
    "for i_enc in range(N_enc_train_10):    # Number of examples\n",
    "\n",
    "    if Data_Frame_10[col_list_10[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "      for i_t in range(150):\n",
    "\n",
    "        y = Data_Frame_10[col_list_10[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "        if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "            Y_TEMP_10.append(y)\n",
    "\n",
    "\n",
    "Y_TEMP_10 = np.array(Y_TEMP_10)\n",
    "len(Y_TEMP_10)\n",
    "\n",
    "\n",
    "N_ratio_10 = np.sum(Y_TEMP_10)/(len(Y_TEMP_10)-np.sum(Y_TEMP_10))\n",
    "N_ratio_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6Fo1ywqyMr4"
   },
   "outputs": [],
   "source": [
    "N_enc_train_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gsbFO89JS_n"
   },
   "outputs": [],
   "source": [
    "# TESTING based on some examples:\n",
    "\n",
    "X_t = []\n",
    "Y_t = []\n",
    "\n",
    "col_list_10 = list(Data_Frame_10)\n",
    "\n",
    "for i_enc in range(N_enc_train_10):   #[N_enc_train_10+10]:    # Number of examples\n",
    "\n",
    "    if Data_Frame_10[col_list_10[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "      for i_t in range(150):\n",
    "        \n",
    "        #=============================== Prepare for Future classification case\n",
    "\n",
    "        y = Data_Frame_10[col_list_10[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "        x = np.zeros(shape=(T,D))\n",
    "\n",
    "        if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "           if y==1:\n",
    "\n",
    "              x[:,0] =  Data_Frame_10[col_list_10[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_10[col_list_10[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_10[col_list_10[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_10[col_list_10[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_10[col_list_10[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_10[col_list_10[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_10[col_list_10[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_10[col_list_10[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_10[col_list_10[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_10[col_list_10[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_10[col_list_10[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_10[col_list_10[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X_t.append(x)\n",
    "              Y_t.append(y)\n",
    "\n",
    "\n",
    "           elif y==0  and (np.random.uniform(low=0.0,high=1.0)<N_ratio_10*Ratio_Times):  # and i_t<T2:    # this \"and i_t<T2\" is to have only examples far away **********\n",
    "\n",
    "\n",
    "              x[:,0] =  Data_Frame_10[col_list_10[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_10[col_list_10[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_10[col_list_10[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_10[col_list_10[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_10[col_list_10[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_10[col_list_10[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_10[col_list_10[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_10[col_list_10[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_10[col_list_10[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_10[col_list_10[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_10[col_list_10[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_10[col_list_10[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X_t.append(x)\n",
    "              Y_t.append(y)\n",
    "\n",
    "\n",
    "        #=================================================================\n",
    "        #-------------------------Delete Variables\n",
    "           del x\n",
    "           del y\n",
    "  \n",
    "        #-------------------------\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "X_test = np.array(X_t)\n",
    "Y_test = np.array(Y_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFaquKpxuvqp"
   },
   "outputs": [],
   "source": [
    "N_enc_train_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQxCrWI1g1mC"
   },
   "outputs": [],
   "source": [
    "### Delete those variables that are not needed any more to use less RAM\n",
    "\n",
    "del Data_Frame_10\n",
    "\n",
    "del Y_TEMP_10\n",
    "\n",
    "del col_list_10\n",
    "\n",
    "del N_enc_train_10\n",
    "\n",
    "del N_ratio_10\n",
    "\n",
    "%del Y_a_10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwYWGJubE2RF"
   },
   "outputs": [],
   "source": [
    "# One-step forecast using true targets\n",
    "\n",
    "outputs = model.predict(X_test)\n",
    "\n",
    "#outputs = new_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Emy9bztAgOwz"
   },
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gx1vkxattQI9"
   },
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRHvedasW8rA"
   },
   "outputs": [],
   "source": [
    "RNN_Class_1 = outputs.flatten()\n",
    "RNN_Class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIerBlFqkVn8"
   },
   "outputs": [],
   "source": [
    "RNN_Class = (RNN_Class_1>0.5)*1\n",
    "RNN_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fx8zEtIm0a_Q"
   },
   "outputs": [],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTAlmNNCfsaf"
   },
   "outputs": [],
   "source": [
    "RNN_Class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHZsPyA_0mma"
   },
   "outputs": [],
   "source": [
    "np.sum(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJ4WKLA003a_"
   },
   "outputs": [],
   "source": [
    "len(Y_test)-np.sum(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4B9Fhdjc0eOm"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKNSny9fluKs"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(Y_test, RNN_Class)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fH_D44d0c85"
   },
   "outputs": [],
   "source": [
    "P_1g1 = confusion_matrix[1][1]/np.sum(Y_test)\n",
    "P_0g1 = confusion_matrix[1][0]/np.sum(Y_test)\n",
    "P_0g0 = confusion_matrix[0][0]/(len(Y_test) - np.sum(Y_test))\n",
    "P_1g0 = confusion_matrix[0][1]/(len(Y_test) - np.sum(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUny89z2e5Lk"
   },
   "outputs": [],
   "source": [
    "P_1g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKTl454sezAJ"
   },
   "outputs": [],
   "source": [
    "P_0g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdNX5jRgfhQg"
   },
   "outputs": [],
   "source": [
    "P_0g0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZydyHt_zfh65"
   },
   "outputs": [],
   "source": [
    "P_1g0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4ufcdiOptNF"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_LJf1O7p8rZ"
   },
   "outputs": [],
   "source": [
    "yhat_classes = model.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWjmUnfRF-oq"
   },
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y_test, RNN_Class)\n",
    "accuracy\n",
    "#print('Accuracy: %f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UQuyr0cGQRc"
   },
   "outputs": [],
   "source": [
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, RNN_Class)\n",
    "precision\n",
    "#print('Precision: %f' % precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IE94pqMsGhgB"
   },
   "outputs": [],
   "source": [
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y_test, RNN_Class)\n",
    "recall\n",
    "#print('Recall: %f' % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIiR47OoGwYn"
   },
   "outputs": [],
   "source": [
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Y_test, RNN_Class)\n",
    "f1\n",
    "#print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdrkXD_rG32j"
   },
   "outputs": [],
   "source": [
    "# kappa\n",
    "kappa = cohen_kappa_score(Y_test, RNN_Class)\n",
    "kappa\n",
    "#print('Cohens kappa: %f' % kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7P2FJ8bJDJs"
   },
   "outputs": [],
   "source": [
    "# ROC AUC\n",
    "auc = roc_auc_score(Y_test, RNN_Class)\n",
    "auc\n",
    "#print('ROC AUC: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4f-_RDWJK-w"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "\n",
    "# ROC AUC\n",
    "fpr, tpr, thresholds = metrics.plot_roc_curve(Y_test, RNN_Class, pos_label=None)\n",
    "\n",
    "#print('ROC AUC: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8LRAtypp78J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Llj4cnl-psqt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CoB_HBJ5pr5Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFZKaOxH7CpV"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, RNN_Class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PepW0I8XF8B"
   },
   "outputs": [],
   "source": [
    "N_enc_train_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAcdybLezjdj"
   },
   "outputs": [],
   "source": [
    "#Data_Frame_11 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_NoisyData_20sec_NEW_10_TestPlot.csv')#, header=None)  \n",
    "\n",
    "Data_Frame_11 = pd.read_csv('/content/drive/My Drive/MITLL_Correlated_RNN_20sec_NEW_10_TestPlot.csv')#, header=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI3V87O4uDsH"
   },
   "outputs": [],
   "source": [
    "Data_Frame_11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWgIhcjPXFbJ"
   },
   "outputs": [],
   "source": [
    "# TESTING based on some examples:\n",
    "\n",
    "X1_t = []\n",
    "Y1_t = []\n",
    "\n",
    "col_list_11 = list(Data_Frame_11)\n",
    "\n",
    "for i_enc in [3]:    # Number of examples: max is N_enc_train_10\n",
    "\n",
    "    if Data_Frame_11[col_list_11[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[0]==-1:\n",
    "\n",
    "      for i_t in range(150):\n",
    "        \n",
    "        #=============================== Prepare for Future classification case\n",
    "\n",
    "        y = Data_Frame_11[col_list_11[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[i_t]\n",
    "\n",
    "        x = np.zeros(shape=(T,D))\n",
    "\n",
    "        if (y==0 or y==1) and i_t>T1-2:\n",
    "\n",
    "           if y==1:\n",
    "\n",
    "              x[:,0] =  Data_Frame_11[col_list_11[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_11[col_list_11[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_11[col_list_11[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_11[col_list_11[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_11[col_list_11[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_11[col_list_11[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_11[col_list_11[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_11[col_list_11[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_11[col_list_11[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_11[col_list_11[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_11[col_list_11[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_11[col_list_11[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X1_t.append(x)\n",
    "              Y1_t.append(y)\n",
    "\n",
    "\n",
    "           elif y==0:\n",
    "\n",
    "\n",
    "              x[:,0] =  Data_Frame_11[col_list_11[i_enc*13 + 2]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,1] =  Data_Frame_11[col_list_11[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,2] =  Data_Frame_11[col_list_11[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,3] =  Data_Frame_11[col_list_11[i_enc*13 + 5]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,4] =  Data_Frame_11[col_list_11[i_enc*13 + 6]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,5] =  Data_Frame_11[col_list_11[i_enc*13 + 7]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,6] =  Data_Frame_11[col_list_11[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,7] =  Data_Frame_11[col_list_11[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,8] =  Data_Frame_11[col_list_11[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,9] =  Data_Frame_11[col_list_11[i_enc*13 + 11]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,10] =  Data_Frame_11[col_list_11[i_enc*13 + 12]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "              x[:,11] =  Data_Frame_11[col_list_11[i_enc*13 + 13]].to_numpy(dtype=float, copy=True)[i_t-T+1:i_t+1]\n",
    "\n",
    "\n",
    "              X1_t.append(x)\n",
    "              Y1_t.append(y)\n",
    "\n",
    "\n",
    "        #=================================================================\n",
    "        #-------------------------Delete Variables\n",
    "           del x\n",
    "           del y\n",
    "  \n",
    "        #-------------------------\n",
    "\n",
    "\n",
    "  \n",
    "X1_test = np.array(X1_t)\n",
    "Y1_test = np.array(Y1_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCNb2Cc1bXNS"
   },
   "outputs": [],
   "source": [
    "### Prepare the above example to plot\n",
    "\n",
    "\n",
    "x_p = np.zeros(shape=(150,D))\n",
    "\n",
    "x_p[:,0] = Data_Frame_11[col_list_11[i_enc*13 + 2]].to_numpy(dtype=float, copy=True) \n",
    "x_p[:,1] = Data_Frame_11[col_list_11[i_enc*13 + 3]].to_numpy(dtype=float, copy=True)\n",
    "x_p[:,2] = Data_Frame_11[col_list_11[i_enc*13 + 4]].to_numpy(dtype=float, copy=True)\n",
    "\n",
    "x_p[:,6] = Data_Frame_11[col_list_11[i_enc*13 + 8]].to_numpy(dtype=float, copy=True)\n",
    "x_p[:,7] = Data_Frame_11[col_list_11[i_enc*13 + 9]].to_numpy(dtype=float, copy=True)\n",
    "x_p[:,8] = Data_Frame_11[col_list_11[i_enc*13 + 10]].to_numpy(dtype=float, copy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9pWUW4LbnNd"
   },
   "outputs": [],
   "source": [
    "### Plot some encounters: Horizontal\n",
    "\n",
    "#=================\n",
    "V_P = plt.subplot(111)\n",
    "#=================    \n",
    "\n",
    "V_P.plot(x_p[:,0], x_p[:,1], 'b', label='Track_1')    \n",
    "V_P.plot(x_p[:,6], x_p[:,7], 'r', label='Track_2')    \n",
    "\n",
    "V_P.plot(x_p[0,0], x_p[0,1], 'Dk')    \n",
    "V_P.plot(x_p[0,6], x_p[0,7], 'Dk')    \n",
    "\n",
    "plt.title('Trajectories (Horizontal)', fontsize=15)\n",
    "\n",
    "#plt.axis([0, 500, 0.0001, 0.05])\n",
    "pylab.legend(loc='center left')\n",
    "#pylab.ylim(-1.5, 2.0)\n",
    "\n",
    "#plt.xlabel('Time (sec)')\n",
    "plt.xlabel('East (nmi)')\n",
    "plt.ylabel('North (nmi)')\n",
    "\n",
    "plt.savefig('Traj_H_exm3.png', dpi=220, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doEb_PDkbmt_"
   },
   "outputs": [],
   "source": [
    "### Plot some encounters:  Vertical\n",
    "\n",
    "#=================\n",
    "V_P = plt.subplot(111)\n",
    "#=================    \n",
    "\n",
    "V_P.plot(x_p[:,2]*1852*3.28084, 'b', label='Track_1')    \n",
    "V_P.plot(x_p[:,8]*1852*3.28084, 'r', label='Track_2')    \n",
    "\n",
    "V_P.plot(x_p[0,2]*1852*3.28084, 'Dk')    \n",
    "V_P.plot(x_p[0,8]*1852*3.28084, 'Dk')    \n",
    "\n",
    "plt.title('Trajectories (Vertical)', fontsize=15)\n",
    "\n",
    "#plt.axis([0, 500, 0.0001, 0.05])\n",
    "pylab.legend(loc='center right')\n",
    "#pylab.ylim(-1.5, 2.0)\n",
    "\n",
    "#plt.xlabel('Time (sec)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Up (ft)')\n",
    "\n",
    "plt.savefig('Traj_V_exm3.png', dpi=220, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwnLuHP9TyAl"
   },
   "outputs": [],
   "source": [
    "### Plot some encounters: Horizontal\n",
    "\n",
    "#=================\n",
    "V_P = plt.subplot(111)\n",
    "#=================    \n",
    "\n",
    "\n",
    "V_P.plot(np.sqrt((x_p[:,0]-x_p[:,6])**2 + (x_p[:,1]-x_p[:,7])**2), 'b', label='Horizontal Distance')    \n",
    "V_P.plot(np.ones(len(x_p[:,0])), 'r', label='Threshold')    \n",
    "\n",
    "\n",
    "plt.title('Distance (Horizontal)', fontsize=15)\n",
    "\n",
    "#plt.axis([0, 500, 0.0001, 0.05])\n",
    "pylab.legend(loc='center left')\n",
    "#pylab.ylim(-1.5, 2.0)\n",
    "\n",
    "#plt.xlabel('Time (sec)')\n",
    "#plt.xlabel('East (nmi)')\n",
    "#plt.ylabel('North (nmi)')\n",
    "\n",
    "#plt.savefig('Traj_H_exm3.png', dpi=220, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdFsvfxsTxNj"
   },
   "outputs": [],
   "source": [
    "### Plot some encounters: Vertical\n",
    "\n",
    "#=================\n",
    "V_P = plt.subplot(111)\n",
    "#=================    \n",
    "\n",
    "\n",
    "V_P.plot(np.abs(x_p[:,2]-x_p[:,8])*1852*3.28084, 'b', label='Vertical Distance')\n",
    "V_P.plot(np.ones(len(x_p[:,0]))*400, 'r', label='Threshold')    \n",
    "\n",
    "\n",
    "plt.title('Distance (Vertical)', fontsize=15)\n",
    "\n",
    "#plt.axis([0, 500, 0.0001, 0.05])\n",
    "pylab.legend(loc='center left')\n",
    "#pylab.ylim(-1.5, 2.0)\n",
    "\n",
    "#plt.xlabel('Time (sec)')\n",
    "#plt.xlabel('East (nmi)')\n",
    "#plt.ylabel('North (nmi)')\n",
    "\n",
    "#plt.savefig('Traj_H_exm3.png', dpi=220, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pA6QePX3cFc_"
   },
   "outputs": [],
   "source": [
    "### Plot some encounters: Horizontal\n",
    "\n",
    "#=================\n",
    "V_P = plt.subplot(111)\n",
    "#=================    \n",
    "\n",
    "\n",
    "V_P.plot((np.sqrt((x_p[:,0]-x_p[:,6])**2 + (x_p[:,1]-x_p[:,7])**2)<1)*1, '.b', label='Horizontal Distance')    \n",
    "V_P.plot(((np.abs(x_p[:,2]-x_p[:,8])*1852*3.28084)<400)*1, 'ok', label='Vertical Distance')\n",
    "\n",
    "yy = np.zeros(len(x_p[:,0]))\n",
    "yy[39:] = Data_Frame_11[col_list_11[i_enc*13 + 14]].to_numpy(dtype=float, copy=True)[19:130]\n",
    "V_P.plot(yy, 'r', label='Truth')\n",
    "\n",
    "\n",
    "plt.title('Class', fontsize=15)\n",
    "\n",
    "#plt.axis([0, 500, 0.0001, 0.05])\n",
    "pylab.legend(loc='center left')\n",
    "#pylab.ylim(-1.5, 2.0)\n",
    "\n",
    "#plt.xlabel('Time (sec)')\n",
    "#plt.xlabel('East (nmi)')\n",
    "#plt.ylabel('North (nmi)')\n",
    "\n",
    "#plt.savefig('Traj_H_exm3.png', dpi=220, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyomPix2Lxsj"
   },
   "outputs": [],
   "source": [
    "#X2_test = X1_test.copy()\n",
    "#X2_test[0] = X2_test[0] + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ul-M2PH3X9Zf"
   },
   "outputs": [],
   "source": [
    "# One-step forecast using true targets\n",
    "\n",
    "outputs_1 = model.predict(X1_test)\n",
    "\n",
    "#outputs_1 = new_model.predict(X1_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZ-Qb8RGX8aU"
   },
   "outputs": [],
   "source": [
    "Y1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUJCG6ATX8DX"
   },
   "outputs": [],
   "source": [
    "Y1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2LA8y7_X7om"
   },
   "outputs": [],
   "source": [
    "RNN_Class_1_1 = outputs_1.flatten()\n",
    "RNN_Class_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgqplpxcZ-jv"
   },
   "outputs": [],
   "source": [
    "RNN_Class_th = (RNN_Class_1_1>0.5)*1\n",
    "RNN_Class_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5do7L1rKPkH"
   },
   "outputs": [],
   "source": [
    "#=================\n",
    "V_P = plt.subplot(111)\n",
    "#=================    \n",
    "V_P.plot(Y1_test, 'Db', label='Truth')    \n",
    "V_P.plot(RNN_Class_1_1, '.r', label='RNN Class Probability')    \n",
    "V_P.plot(RNN_Class_th, 'k', label='RNN Class')    \n",
    "\n",
    "\n",
    "plt.title('Classes and RNN Probability Outputs', fontsize=15)\n",
    "\n",
    "#plt.axis([0, 500, 0.0001, 0.05])\n",
    "pylab.legend(loc='center left')\n",
    "#pylab.ylim(-1.5, 2.0)\n",
    "\n",
    "#plt.xlabel('Time (sec)')\n",
    "#plt.ylabel('Class')\n",
    "\n",
    "plt.savefig('Conflict_Class_Predict_exm3_20sec.png', dpi=220, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9O0fW0FgcCsZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4afvx-HcCH7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPDkxqE1wQ_M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MO3Zrh4iwc7M"
   },
   "source": [
    "Probabilities obtained based on confusion matrix:\n",
    "\n",
    "P(1|1) = 0.97627           (first try it was 0.97)\n",
    "\n",
    "P(0|1) = 0.02372        (first try it was 0.03)\n",
    "\n",
    "P(0|0) = 0.89637           (first try it was 0.8)\n",
    "\n",
    "P(1|0) = 0.10362           (first try it was 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKY0F9uFoUvw"
   },
   "outputs": [],
   "source": [
    "### Prepare the above example to plot\n",
    "\n",
    "i_enc_exm = N_enc_train_1+4\n",
    "\n",
    "x_p = np.zeros(shape=(150,D))\n",
    "\n",
    "x_p[:,0] = Data_Frame_1[col_list_1[i_enc_exm*13 + 2]].to_numpy(dtype=float, copy=True)\n",
    "x_p[:,1] = Data_Frame_1[col_list_1[i_enc_exm*13 + 3]].to_numpy(dtype=float, copy=True)\n",
    "x_p[:,2] = Data_Frame_1[col_list_1[i_enc_exm*13 + 4]].to_numpy(dtype=float, copy=True)\n",
    "\n",
    "x_p[:,6] = Data_Frame_1[col_list_1[i_enc_exm*13 + 8]].to_numpy(dtype=float, copy=True)\n",
    "x_p[:,7] = Data_Frame_1[col_list_1[i_enc_exm*13 + 9]].to_numpy(dtype=float, copy=True)\n",
    "x_p[:,8] = Data_Frame_1[col_list_1[i_enc_exm*13 + 10]].to_numpy(dtype=float, copy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GA9Gb6LCo3Sa"
   },
   "outputs": [],
   "source": [
    "### Plot some encounters: Horizontal\n",
    "\n",
    "#=================\n",
    "V_P = plt.subplot(111)\n",
    "#=================    \n",
    "\n",
    "V_P.plot(x_p[:,0], x_p[:,1], '.b', label='Track_1')    \n",
    "V_P.plot(x_p[:,6], x_p[:,7], '.r', label='Track_2')    \n",
    "\n",
    "V_P.plot(x_p[0,0], x_p[0,1], 'Dr')    \n",
    "V_P.plot(x_p[0,6], x_p[0,7], 'Db')    \n",
    "\n",
    "plt.title('Trajectories (Horizontal)', fontsize=15)\n",
    "\n",
    "#plt.axis([0, 500, 0.0001, 0.05])\n",
    "pylab.legend(loc='center right')\n",
    "#pylab.ylim(-1.5, 2.0)\n",
    "\n",
    "#plt.xlabel('Time (sec)')\n",
    "plt.xlabel('East (nmi)')\n",
    "plt.ylabel('North (nmi)')\n",
    "\n",
    "#plt.savefig('Traj_H_exm1.png', dpi=220, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSRFq6Tpo224"
   },
   "outputs": [],
   "source": [
    "### Plot some encounters:  Vertical\n",
    "\n",
    "#=================\n",
    "V_P = plt.subplot(111)\n",
    "#=================    \n",
    "\n",
    "V_P.plot(x_p[:,2]*1852*3.28084, '.b', label='Track_1')    \n",
    "V_P.plot(x_p[:,8]*1852*3.28084, '.r', label='Track_2')    \n",
    "\n",
    "V_P.plot(x_p[0,2]*1852*3.28084, 'Dr')    \n",
    "V_P.plot(x_p[0,8]*1852*3.28084, 'Db')    \n",
    "\n",
    "plt.title('Trajectories (Vertical)', fontsize=15)\n",
    "\n",
    "#plt.axis([0, 500, 0.0001, 0.05])\n",
    "pylab.legend(loc='center right')\n",
    "#pylab.ylim(-1.5, 2.0)\n",
    "\n",
    "#plt.xlabel('Time (sec)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Up (ft)')\n",
    "\n",
    "#plt.savefig('Traj_V_exm1.png', dpi=220, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpRjj29no2D4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bG2NTtaKpxon"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "193MIJg_3mgB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hy3QF9R33mCk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5s-Srbvp3lLJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06l2kBbv3jJv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_MITLL_NMAC_Classification_MoreData.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
